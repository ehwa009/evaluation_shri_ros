<launch>
    <arg name="use_nao_speech" default="true" />
    <arg name="nao_ip" default="192.168.66.100" />
    <arg name="gaze_default_height" default="0.4" />
    <arg name='use_v1_arbiter' default="false" />

    <arg name="camera_offset_x" default="-0.80" />
    <arg name="camera_offset_y" default="0.55" />
    <arg name="camera_offset_z" default="0.33" />
    <arg name="camera_offset_roll" default="0.0" />
    <arg name="camera_offset_pitch" default="0.0" />
    <arg name="camera_offset_yaw" default="0.0" />

    <arg name="robot_offset_x" default="0.0" />
    <arg name="robot_offset_y" default="0.0" />
    <arg name="robot_offset_z" default="0.72" />

    <arg name="user_number" default="0" />


    <!-- For Social Mind Bringup -->
    <include file="$(find social_mind)/launch/bringup.launch">
        <arg name="project_path" value="~/shri_projects/evaluation_shri" />
        <arg name="gaze" default="false" />
        <arg name="use_v1_arbiter" value="$(arg use_v1_arbiter)" />
        <arg name="fake_render_speech" default="false" />
        <arg name="fake_render_gesture" default="false" />
        <arg name="fake_render_facial_expression" default="true" />
    </include>

    <!-- For NAO Bringup -->
    <include file="$(find nao_shri_bringup)/launch/bringup.launch">
        <arg name="use_nao_speech" value="$(arg use_nao_speech)" />
        <arg name="nao_ip" value="$(arg nao_ip)" />
    </include>

    <node name="static_robot_tf_publisher" type="static_transform_publisher" pkg="tf2_ros"
        args="$(arg robot_offset_x) $(arg robot_offset_y) $(arg robot_offset_z) 0 0 0 world odom"
        output="screen" />

    <!-- For Google Cloud Speech -->
    <include file="$(find google_cloud_speech)/launch/bringup.launch">
        <arg name="timeout_for_silency_detect" value="10.0" />
        <arg name="always_listening" value="false" />
    </include>
    <node name="sp_speech_recognizer" type="percep_speech.py" pkg="evaluation_shri_y2_perceptions" output="screen">
        <param name="config_file" value="$(find evaluation_shri_y2_perceptions)/config/percep_speech_conf.yaml" />
    </node>

    <!-- Dialog System -->
    <include file="$(find dialogue_system)/launch/bringup.launch">
        <arg name="user_number" value="$(arg user_number)" />
    </include>
    
    <!-- For Nuitrack -->
    <!-- <include file="$(find nuitrack_ros)/launch/nuitrack.launch">
        <arg name="use_openni2" value="false"/>
        <arg name="use_realsense" value="true"/>

        <arg name="offset_x" value="$(arg camera_offset_x)" />
        <arg name="offset_y" value="$(arg camera_offset_y)" />
        <arg name="offset_z" value="$(arg camera_offset_z)" />
        <arg name="offset_roll" value="$(arg camera_offset_roll)" />
        <arg name="offset_pitch" value="$(arg camera_offset_pitch)" />
        <arg name="offset_yaw" value="$(arg camera_offset_yaw)" />
    </include> -->

    <!-- <node name="sp_face_detector" type="percep_face_detect.py" pkg="evaluation_shri_y2_perceptions" output="screen">
        <param name="config_file" value="$(find evaluation_shri_y2_perceptions)/config/percep_face_detection_conf.yaml" />
    </node> -->

    <!-- For Polly Speech -->
    <!-- <include file="$(find polly_speech)/launch/bringup.launch" unless="$(arg use_nao_speech)" />
    <node name="render_speech" type="render_speech.py" pkg="evaluation_shri_y2_renders" output="screen" unless="$(arg use_nao_speech)">
        <param name="use_multi_speech" value="false" />
    </node> -->

    <!-- For Commmand GUI -->
    <node name="command_buttons" type="rqt_shri_command_buttons" pkg="rqt_shri_command_buttons" output="screen"/>
</launch>